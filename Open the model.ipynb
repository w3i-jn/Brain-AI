{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06588ed2-085a-4a7f-99e0-83f24433c7f0",
   "metadata": {},
   "source": [
    "# Check packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b4f0236-e5f9-48d4-afe9-03ef9b945f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenVINO version:  2024.0.0-14509-34caeefd078-releases/2024/0\n"
     ]
    }
   ],
   "source": [
    "import openvino as ov\n",
    "\n",
    "print(\"OpenVINO version: \", ov.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac234d3c-90c0-4e70-a798-b1501bbc1e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openvino version: 2024.0.0\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "package_name = \"openvino\"\n",
    "\n",
    "try:\n",
    "    distribution = pkg_resources.get_distribution(package_name)\n",
    "    version = distribution.version\n",
    "    print(f\"{package_name} version: {version}\")\n",
    "except pkg_resources.DistributionNotFound:\n",
    "    print(f\"{package_name} is not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84b32a4-3983-4bf8-bf4f-26676b69befb",
   "metadata": {},
   "source": [
    "# Open Model Zoo (OMZ) DownloaderÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3eb14f-6f53-4fe8-b89c-8f8fa2c65bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: omz_downloader [-h] [--name PAT[,PAT...]] [--list FILE.LST] [--all]\n",
      "                      [--print_all] [--precisions PREC[,PREC...]] [-o DIR]\n",
      "                      [--cache_dir DIR] [--num_attempts N]\n",
      "                      [--progress_format {text,json}] [-j N]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --name PAT[,PAT...]   download only models whose names match at least one of\n",
      "                        the specified patterns\n",
      "  --list FILE.LST       download only models whose names match at least one of\n",
      "                        the patterns in the specified file\n",
      "  --all                 download all available models\n",
      "  --print_all           print all available models\n",
      "  --precisions PREC[,PREC...]\n",
      "                        download only models with the specified precisions\n",
      "                        (actual for DLDT networks); specify one or more of:\n",
      "                        FP32,FP16,FP32-INT8,FP16-INT1,FP16-INT8,FP32-INT1\n",
      "  -o DIR, --output_dir DIR\n",
      "                        path where to save models\n",
      "  --cache_dir DIR       directory to use as a cache for downloaded files\n",
      "  --num_attempts N      attempt each download up to N times\n",
      "  --progress_format {text,json}\n",
      "                        which format to use for progress reporting\n",
      "  -j N, --jobs N        how many downloads to perform concurrently\n"
     ]
    }
   ],
   "source": [
    "! omz_downloader -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca910c39-ed01-43f8-94fe-038305bde5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclnet\n",
      "aclnet-int8\n",
      "action-recognition-0001\n",
      "age-gender-recognition-retail-0013\n",
      "anti-spoof-mn3\n",
      "asl-recognition-0004\n",
      "background-matting-mobilenetv2\n",
      "bert-base-ner\n",
      "bert-large-uncased-whole-word-masking-squad-0001\n",
      "bert-large-uncased-whole-word-masking-squad-emb-0001\n",
      "bert-large-uncased-whole-word-masking-squad-int8-0001\n",
      "bert-small-uncased-whole-word-masking-squad-0001\n",
      "bert-small-uncased-whole-word-masking-squad-0002\n",
      "bert-small-uncased-whole-word-masking-squad-emb-int8-0001\n",
      "bert-small-uncased-whole-word-masking-squad-int8-0002\n",
      "brain-tumor-segmentation-0002\n",
      "cocosnet\n",
      "colorization-siggraph\n",
      "colorization-v2\n",
      "common-sign-language-0001\n",
      "common-sign-language-0002\n",
      "convnext-tiny\n",
      "ctdet_coco_dlav0_512\n",
      "ctpn\n",
      "deeplabv3\n",
      "densenet-121-tf\n",
      "detr-resnet50\n",
      "dla-34\n",
      "driver-action-recognition-adas-0002\n",
      "drn-d-38\n",
      "efficientdet-d0-tf\n",
      "efficientdet-d1-tf\n",
      "efficientnet-b0\n",
      "efficientnet-b0-pytorch\n",
      "efficientnet-v2-b0\n",
      "efficientnet-v2-s\n",
      "emotions-recognition-retail-0003\n",
      "erfnet\n",
      "f3net\n",
      "face-detection-0200\n",
      "face-detection-0202\n",
      "face-detection-0204\n",
      "face-detection-0205\n",
      "face-detection-0206\n",
      "face-detection-adas-0001\n",
      "face-detection-retail-0004\n",
      "face-detection-retail-0005\n",
      "face-recognition-resnet100-arcface-onnx\n",
      "face-reidentification-retail-0095\n",
      "faceboxes-pytorch\n",
      "facenet-20180408-102900\n",
      "facial-landmarks-35-adas-0002\n",
      "facial-landmarks-98-detection-0001\n",
      "fast-neural-style-mosaic-onnx\n",
      "faster-rcnn-resnet101-coco-sparse-60-0001\n",
      "faster_rcnn_inception_resnet_v2_atrous_coco\n",
      "faster_rcnn_resnet50_coco\n",
      "fastseg-large\n",
      "fastseg-small\n",
      "fbcnn\n",
      "fcrn-dp-nyu-depth-v2-tf\n",
      "formula-recognition-medium-scan-0001\n",
      "formula-recognition-polynomials-handwritten-0001\n",
      "forward-tacotron\n",
      "gaze-estimation-adas-0002\n",
      "gmcnn-places2-tf\n",
      "googlenet-v1-tf\n",
      "googlenet-v2-tf\n",
      "googlenet-v3\n",
      "googlenet-v3-pytorch\n",
      "googlenet-v4-tf\n",
      "gpt-2\n",
      "handwritten-english-recognition-0001\n",
      "handwritten-japanese-recognition-0001\n",
      "handwritten-score-recognition-0003\n",
      "handwritten-simplified-chinese-recognition-0001\n",
      "hbonet-0.25\n",
      "hbonet-1.0\n",
      "head-pose-estimation-adas-0001\n",
      "higher-hrnet-w32-human-pose-estimation\n",
      "horizontal-text-detection-0001\n",
      "hrnet-v2-c1-segmentation\n",
      "human-pose-estimation-0001\n",
      "human-pose-estimation-0005\n",
      "human-pose-estimation-0006\n",
      "human-pose-estimation-0007\n",
      "human-pose-estimation-3d-0001\n",
      "hybrid-cs-model-mri\n",
      "i3d-rgb-tf\n",
      "icnet-camvid-ava-0001\n",
      "icnet-camvid-ava-sparse-30-0001\n",
      "icnet-camvid-ava-sparse-60-0001\n",
      "image-retrieval-0001\n",
      "inception-resnet-v2-tf\n",
      "instance-segmentation-person-0007\n",
      "instance-segmentation-security-0002\n",
      "instance-segmentation-security-0091\n",
      "instance-segmentation-security-0228\n",
      "instance-segmentation-security-1039\n",
      "instance-segmentation-security-1040\n",
      "landmarks-regression-retail-0009\n",
      "levit-128s\n",
      "license-plate-recognition-barrier-0001\n",
      "license-plate-recognition-barrier-0007\n",
      "machine-translation-nar-de-en-0002\n",
      "machine-translation-nar-en-de-0002\n",
      "machine-translation-nar-en-ru-0002\n",
      "machine-translation-nar-ru-en-0002\n",
      "mask_rcnn_inception_resnet_v2_atrous_coco\n",
      "mask_rcnn_resnet50_atrous_coco\n",
      "midasnet\n",
      "mixnet-l\n",
      "mobilenet-v1-0.25-128\n",
      "mobilenet-v1-1.0-224-tf\n",
      "mobilenet-v2-1.0-224\n",
      "mobilenet-v2-1.4-224\n",
      "mobilenet-v2-pytorch\n",
      "mobilenet-v3-large-1.0-224-tf\n",
      "mobilenet-v3-small-1.0-224-tf\n",
      "mobilenet-yolo-v4-syg\n",
      "modnet-photographic-portrait-matting\n",
      "modnet-webcam-portrait-matting\n",
      "mozilla-deepspeech-0.6.1\n",
      "mozilla-deepspeech-0.8.2\n",
      "nanodet-m-1.5x-416\n",
      "nanodet-plus-m-1.5x-416\n",
      "netvlad-tf\n",
      "nfnet-f0\n",
      "noise-suppression-denseunet-ll-0001\n",
      "noise-suppression-poconetlike-0001\n",
      "open-closed-eye-0001\n",
      "pedestrian-and-vehicle-detector-adas-0001\n",
      "pedestrian-detection-adas-0002\n",
      "person-attributes-recognition-crossroad-0230\n",
      "person-attributes-recognition-crossroad-0234\n",
      "person-attributes-recognition-crossroad-0238\n",
      "person-detection-0106\n",
      "person-detection-0200\n",
      "person-detection-0201\n",
      "person-detection-0202\n",
      "person-detection-0203\n",
      "person-detection-0301\n",
      "person-detection-0302\n",
      "person-detection-0303\n",
      "person-detection-action-recognition-0005\n",
      "person-detection-action-recognition-0006\n",
      "person-detection-action-recognition-teacher-0002\n",
      "person-detection-asl-0001\n",
      "person-detection-raisinghand-recognition-0001\n",
      "person-detection-retail-0002\n",
      "person-detection-retail-0013\n",
      "person-reidentification-retail-0277\n",
      "person-reidentification-retail-0286\n",
      "person-reidentification-retail-0287\n",
      "person-reidentification-retail-0288\n",
      "person-vehicle-bike-detection-2000\n",
      "person-vehicle-bike-detection-2001\n",
      "person-vehicle-bike-detection-2002\n",
      "person-vehicle-bike-detection-2003\n",
      "person-vehicle-bike-detection-2004\n",
      "person-vehicle-bike-detection-crossroad-0078\n",
      "person-vehicle-bike-detection-crossroad-1016\n",
      "person-vehicle-bike-detection-crossroad-yolov3-1020\n",
      "product-detection-0001\n",
      "pspnet-pytorch\n",
      "quartznet-15x5-en\n",
      "regnetx-3.2gf\n",
      "repvgg-a0\n",
      "repvgg-b1\n",
      "repvgg-b3\n",
      "resnest-50-pytorch\n",
      "resnet-18-pytorch\n",
      "resnet-34-pytorch\n",
      "resnet-50-pytorch\n",
      "resnet-50-tf\n",
      "resnet18-xnor-binary-onnx-0001\n",
      "resnet50-binary-0001\n",
      "retinaface-resnet50-pytorch\n",
      "retinanet-tf\n",
      "rexnet-v1-x1.0\n",
      "rfcn-resnet101-coco-tf\n",
      "road-segmentation-adas-0001\n",
      "robust-video-matting-mobilenetv3\n",
      "semantic-segmentation-adas-0001\n",
      "shufflenet-v2-x1.0\n",
      "single-human-pose-estimation-0001\n",
      "single-image-super-resolution-1032\n",
      "single-image-super-resolution-1033\n",
      "smartlab-action-recognition-0001\n",
      "smartlab-object-detection-0001\n",
      "smartlab-object-detection-0002\n",
      "smartlab-object-detection-0003\n",
      "smartlab-object-detection-0004\n",
      "smartlab-sequence-modelling-0001\n",
      "smartlab-sequence-modelling-0002\n",
      "ssd-resnet34-1200-onnx\n",
      "ssd_mobilenet_v1_coco\n",
      "ssd_mobilenet_v1_fpn_coco\n",
      "ssdlite_mobilenet_v2\n",
      "swin-tiny-patch4-window7-224\n",
      "t2t-vit-14\n",
      "text-detection-0003\n",
      "text-detection-0004\n",
      "text-image-super-resolution-0001\n",
      "text-recognition-0012\n",
      "text-recognition-0014\n",
      "text-recognition-0015\n",
      "text-recognition-0016\n",
      "text-recognition-resnet-fc\n",
      "text-spotting-0005\n",
      "text-to-speech-en-0001\n",
      "text-to-speech-en-multi-0001\n",
      "time-series-forecasting-electricity-0001\n",
      "ultra-lightweight-face-detection-rfb-320\n",
      "ultra-lightweight-face-detection-slim-320\n",
      "unet-camvid-onnx-0001\n",
      "vehicle-attributes-recognition-barrier-0039\n",
      "vehicle-attributes-recognition-barrier-0042\n",
      "vehicle-detection-0200\n",
      "vehicle-detection-0201\n",
      "vehicle-detection-0202\n",
      "vehicle-detection-adas-0002\n",
      "vehicle-license-plate-detection-barrier-0106\n",
      "vehicle-license-plate-detection-barrier-0123\n",
      "vehicle-reid-0001\n",
      "vitstr-small-patch16-224\n",
      "wav2vec2-base\n",
      "wavernn\n",
      "weld-porosity-detection-0001\n",
      "yolact-resnet50-fpn-pytorch\n",
      "yolo-v1-tiny-tf\n",
      "yolo-v2-ava-0001\n",
      "yolo-v2-ava-sparse-35-0001\n",
      "yolo-v2-ava-sparse-70-0001\n",
      "yolo-v2-tf\n",
      "yolo-v2-tiny-ava-0001\n",
      "yolo-v2-tiny-ava-sparse-30-0001\n",
      "yolo-v2-tiny-ava-sparse-60-0001\n",
      "yolo-v2-tiny-tf\n",
      "yolo-v2-tiny-vehicle-detection-0001\n",
      "yolo-v3-onnx\n",
      "yolo-v3-tf\n",
      "yolo-v3-tiny-onnx\n",
      "yolo-v3-tiny-tf\n",
      "yolo-v4-tf\n",
      "yolo-v4-tiny-tf\n",
      "yolof\n",
      "yolox-tiny\n"
     ]
    }
   ],
   "source": [
    "! omz_downloader --print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b6bc0-0979-4dcd-875f-f3098fcd3625",
   "metadata": {},
   "source": [
    "# Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156842d0-9df2-4e43-9f0d-891e022a941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading age-gender-recognition-retail-0013 ||################\n",
      "\n",
      "========== Downloading C:\\BrainAI\\OpenVINO101_Project\\intel\\age-gender-recognition-retail-0013\\FP16\\age-gender-recognition-retail-0013.xml\n",
      "... 100%, 42 KB, 247 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading C:\\BrainAI\\OpenVINO101_Project\\intel\\age-gender-recognition-retail-0013\\FP16\\age-gender-recognition-retail-0013.bin\n",
      "... 24%, 1024 KB, 1170 KB/s, 0 seconds passed\n",
      "... 49%, 2048 KB, 1846 KB/s, 1 seconds passed\n",
      "... 73%, 3072 KB, 2489 KB/s, 1 seconds passed\n",
      "... 98%, 4096 KB, 3084 KB/s, 1 seconds passed\n",
      "... 100%, 4175 KB, 3109 KB/s, 1 seconds passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! omz_downloader --name age-gender-recognition-retail-0013 --precision FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac7c83b-e668-49d6-9e0d-40fb68e49afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
